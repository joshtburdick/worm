\documentclass{article}

\usepackage{amsmath}
\usepackage{hyperref}

\newcommand{\funname}[1]{\texttt{#1}}

\title{Noise in the sort matrix}
\author{Josh Burdick}

\begin{document}

\maketitle

<<intro,echo=FALSE,cache=FALSE>>=
opts_chunk$set(cache=TRUE, autodep=TRUE)
library("MASS")
wd = getwd()
setwd("../../../..")
source("git/utils.r")
source("git/unmix/ml/unmix_sort_fraction_ml_1.r")
source("git/unmix/ml/sampleData1.r")
source("git/unmix/ept/practice/invgamma.r")

setwd("git/unmix/unmix_comp/src/")
# print(getwd())
# source("sampling/cdaCpp.r")
setwd(wd)

# allow caching
opts_chunk$set(cache=FALSE, autodep=TRUE)
@


\section{Some test data}

Before doing anything else, I define a tiny test data set, for these reasons:

\begin{itemize}

\item Any parameter tuning won't invalidate results on the real data. (Previously,
I was subsetting to, e.g., the most highly expressed genes.)

\item It may be easier to see if unmixing is working on a toy example.

\item Speed is not the biggest concern.

\end{itemize}

Here, the sort matrix is A, and the expression is X.
Note that since rows of A and X all add up to one, this is also
the case for the rows of B (they are all ``row-stochastic.'')


<<sum1,echo=TRUE>>=
apply(sd0$a, 1, sum)
apply(sd0$x, 1, sum)
apply(sd0$b, 1, sum)
@

One definition of ``working'' would be: if we unmix using a perturbed prior for
A (but using the {\em actual} sort matrix in simulating B), then the posterior
estimate for A is closer to the actual A than the prior.

<<run1,echo=TRUE>>=
p = prior.1(sd0, 10, 2)
# r = unmix.expr.and.sort.matrix.1(p$a.prior, p$x.prior, sd0$b, max.iters=5)
@




\subsection{Distribution of AX}

If we sample from A and X, we should be able to estimate the marginal distributions
of AX by moment-matching...





\section{EP, with an approximate sort matrix}

FIXME this should probably be in a different document.

So far, we've been treating the sort matrix $A$ as exactly known,
which seems like a weak assumption. Therefore, we assume that
its entries are drawn from a gamma distribution, and that
we have a constraint as before.

\begin{align*}
A_{i,j} &\sim \mathrm{Gamma}(\alpha_{i,j},\beta_{i,j}) \\
AX &= b
\end{align*}

If $A$ is known exactly, then I think I know how to approximate
the mean and variance of $X$. However, I don't know how to
modify that method if $A$ is approximate. Therefore, I'm
trying to use EP again.

\subsection{Breaking apart the constraint}

As a toy example of this, we can sample from the
marginals with two constraints, compared to applying
one constraint at a time. This is sort of like assuming
the covariance is diagonal.

If the system is fairly underdetermined, this seems like a
reasonable approximation. Presumably, it will do worse
in a more determined situation (that is, if the number
of sort fractions approaches the number of cells.) We
ignore this for now.

\subsection{Approximating one constraint}

Having done this, we estimate the marginals for each
constraint separately. We do this essentially by
scaling the unit simplex (as I described earlier.)
Without loss of generality, we can assume the constraint
adds up to 1:

\[
A_1 X_1 + A_2 X_2 + ... + A_n X_n = 1
\]

One wrinkle is that $A$ is not known exactly; we assume that
$A$ has a gamma distribution.
This means that $\frac{1}{A_i}$ has
an inverse gamma distribution. If $A$'s shape is at least
2, then we can find the mean and variance of $\frac{1}{A_i}$.
We then moment-match, using the fact that $E[XY] = E[X]E[Y]$.
(The inverse-gamma mean and/or variance aren't well-defined if the
shape is 2 or less.)

(Note that we can't simply {\em divide} the moments of $A$. However,
if we can find the moments of $1/A$, at least approximately, then
we can multiply by them.)

This raises the question of how well a gamma distribution
approximates an inverse gamma distribution. As a quick empirical check
of this, here are some inverse gamma distributions, together with a
moment-matched gamma approximation. (The rate of the inverse gamma presumably
doesn't matter.)


<<invGammaCheck,echo=TRUE>>=
ig.params = rbind(a=c(2.1,2.5,3,5,10,100), b=c(1,1,1,1,1,1))
ig.params
ig.s2mv(ig.params)
gamma.mv2s(ig.s2mv(ig.params))
@


\subsection{Applying EP}

We now (maybe) have a situation similar to that
described by Minka: several approximations which we can
iteratively improve.




\subsection{Comparison with sampling}


I don't have a strategy for sampling when there's noise
in the sort matrix.


\section{Damping and convergence}

One issue with EP is getting it to converge.

Let $x$ be the (natural) parameters of EP, and $f$ be a function that
does one round of EP updates. Basic EP repeatedly applies $f$ to update $x$.

\[x_{new} \leftarrow f(x)\]

This EP update rule sometimes converges, and sometimes doesn't.
It is only provably known to converge on certain types of problems [CITE Minka].
(In contrast, expectation maximization is guaranteed to converge
to a local maximum of the likelihood, although not neccessarily a global maximum.)

Various modifications have been introduced to address this.
One of the simplest modifications, {\em damping}, reduces how much EP ``moves''
in a particular direction. Let $\alpha$ be the amount of damping, which is
at least 0 (no
damping) and less than 1 (no update.) A damped EP update is

\[x_{new} \leftarrow (1-\alpha)f(x) + \alpha x\]

(FIXME is this the usual $\alpha$ definition?)

Using a sufficiently small $\alpha$ can guarantee convergence, at the expense
of requiring more updates [CITE Minka?]. Often, $\alpha$ is chosen empirically,
by choosing the smallest amount of damping which still converges.

One approach to choosing $\alpha$ is to define an objective function as follows:

\[g(x) = \sum_i |[f(x) - x]_i|\]

$g(x) = 0$ if and only if $x$ is a fixed point of $f$ (which is what we're looking for).
We can apply existing methods to minimize $g$. One option might be to do line search
between $x$ and $f(x)$, minimizing $g$ along this line.


\end{document}

